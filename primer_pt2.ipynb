{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fee6977",
   "metadata": {},
   "source": [
    "# Welcome to Part 2 of the BIOL 1595 Python Primer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccc549",
   "metadata": {},
   "source": [
    "Part 2 of this primer will cover an intro to NumPy and Pandas, working with files, and an intro to scikit-learn. The goal for this section is to show you how to use these common techniques that you will likely be using in future coding assignments for BIOL 1595."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fe0e7",
   "metadata": {},
   "source": [
    "## 5. Intro to NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf1fb7",
   "metadata": {},
   "source": [
    "In this section, we will go over the basics of NumPy, one of the most commonly used Python libraries. This will make handling data much more efficient and allows us to use built-in functions so we don't have to write them ourselves! We won't cover everything NumPy has to offer, so be sure to check out the documentation for each of them if you ever get stuck.\n",
    "\n",
    "One of the key aspects of NumPy is that it allows for element wise operations. This just means we can modify data in numpy arrays (numpy's version of lists) more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a08073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "<class 'numpy.ndarray'>\n",
      "[ 2  4  6  8 10]\n",
      "[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Example 5.1 NumPy Arrays and Element Wise Operations\n",
    "\n",
    "# Create a NumPy array from a Python list\n",
    "nums = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(nums)\n",
    "print(type(nums))\n",
    "\n",
    "nums = nums * 2 # Element wise operation: multiply each element by 2\n",
    "print(nums)\n",
    "\n",
    "#Without numpy, you would have to do this with a for loop:\n",
    "new_nums = []\n",
    "for num in [1, 2, 3, 4, 5]:\n",
    "    new_nums.append(num * 2)\n",
    "print(new_nums)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46deb67e",
   "metadata": {},
   "source": [
    "Similarly, we can do something called boolean masking with numpy arrays. This is a type of filtering where we can remove or manipulate data in an array based on if it satisfies some condition. Note that we do something similar in example 2.3, list comprehension, in part 1 of the primer. But the advantage of boolean masking, which only works with numpy arrays, is that it is faster and more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True  True  True]\n",
      "[30 35 40]\n"
     ]
    }
   ],
   "source": [
    "#Example 5.2 Boolean Masking\n",
    "\n",
    "# Create a NumPy array\n",
    "data = np.array([10, 15, 20, 25, 30, 35, 40])\n",
    "# Create a boolean mask for values greater than 25\n",
    "mask = data > 25\n",
    "print(mask)\n",
    "print(data[mask]) # Use the mask to filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623f6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 86.25\n",
      "Median: 86.5\n",
      "Min: 72\n",
      "Max: 110\n",
      "Std: 11.255554184490428\n",
      "Sorted data: [ 72  75  78  85  88  90  92 110]\n",
      "Unique data: [ 72  75  78  85  88  90  92 110]\n",
      "Filtered data: [  0   0   0  90  85  88 110  92]\n"
     ]
    }
   ],
   "source": [
    "#Example 5.3: Common numpy functions\n",
    "\n",
    "data = np.array([72, 75, 78, 90, 85, 88, 110, 92])\n",
    "\n",
    "#Summary statistics\n",
    "mean = np.mean(data)\n",
    "median = np.median(data)\n",
    "min = np.min(data)\n",
    "max = np.max(data)\n",
    "std = np.std(data)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Min:\", min)\n",
    "print(\"Max:\", max)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "sorted_data = np.sort(data)\n",
    "unique_data = np.unique(data)\n",
    "filtered_data = np.where(data > 80, data, 0) # Replace values greater than 80 with themselves, and others with 0\n",
    "print(\"Sorted data:\", sorted_data)\n",
    "print(\"Unique data:\", unique_data)\n",
    "print(\"Filtered data:\", filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44e85b",
   "metadata": {},
   "source": [
    "## 6. Working with Files and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1ad62",
   "metadata": {},
   "source": [
    "Data is almost always stored in some type of files, so extracting the necessary information and storing it in data structures so we can work with it is important. While we can read and write files with normal python, Pandas is a library that makes this simpler by introducing DataFrames, a new type of data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96fca19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age,Sex,Chest pain type,BP,Cholesterol,FBS over 120,EKG results,Max HR,Exercise angina,ST depression,Slope of ST,Number of vessels fluro,Thallium,Heart Disease\n",
      "\n",
      "70,1,4,130,322,0,2,109,0,2.4,2,3,3,Presence\n",
      "\n",
      "Age,Sex,Chest pain type,BP,Cholesterol,FBS over 120,EKG results,Max HR,Exercise angina,ST depression,Slope of ST,Number of vessels fluro,Thallium,Heart Disease\n",
      "\n",
      "70,1,4,130,322,0,2,109,0,2.4,2,3,3,Presence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example 6.1: Reading CSV files with regular Python\n",
    "\n",
    "#Open the file for reading\n",
    "with open('data/hd_data.csv', 'r') as file:\n",
    "    #the readline() function only reads one line at a time and returns strings\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "\n",
    "with open('data/hd_data.csv', 'r') as file:\n",
    "    #the readlines() function reads all lines and returns a list of strings\n",
    "    lines = file.readlines()\n",
    "    print(lines[0]) # Print the header\n",
    "    print(lines[1]) # Print the first data row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6be55",
   "metadata": {},
   "source": [
    "This way of reading files isn't very helpful, since we have a lot of uneccessary characters in the returned strings, like the commas, and have no way of selecting values in a specific column. We will instead use the split and strip functions covered in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005c75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: ['70', '67', '57', '64', '74']\n",
      "Cholesterol: ['322', '564', '261', '263', '269']\n"
     ]
    }
   ],
   "source": [
    "ages = []\n",
    "cholesterol = []\n",
    "\n",
    "with open('data/hd_data.csv', 'r') as file:\n",
    "    #recall that strip() removes the whitespace characters,\n",
    "    #and split() splits the string into a list based on the specified delimiter, in this case \",\"\n",
    "    header = file.readline().strip().split(\",\")\n",
    "    ages_index = header.index(\"Age\")\n",
    "    cholesterol_index = header.index(\"Cholesterol\")\n",
    "\n",
    "    for line in file: #another way to read all lines in a file\n",
    "        values = line.strip().split(\",\")\n",
    "\n",
    "        ages.append(values[ages_index])\n",
    "        cholesterol.append(values[cholesterol_index])\n",
    "\n",
    "#Print first 5 elements in each list\n",
    "print(\"Ages:\", ages[:5])  \n",
    "print(\"Cholesterol:\", cholesterol[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf5ccc",
   "metadata": {},
   "source": [
    "We will now use Panda's DataFrame object. Using the read_csv() function, pandas can automatically read the csv file and assign column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bf0288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
      "0   70    1                4  130          322             0            2   \n",
      "1   67    0                3  115          564             0            2   \n",
      "2   57    1                2  124          261             0            0   \n",
      "3   64    1                4  128          263             0            0   \n",
      "4   74    0                2  120          269             0            2   \n",
      "\n",
      "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
      "0     109                0            2.4            2   \n",
      "1     160                0            1.6            2   \n",
      "2     141                0            0.3            1   \n",
      "3     105                1            0.2            2   \n",
      "4     121                1            0.2            1   \n",
      "\n",
      "   Number of vessels fluro  Thallium Heart Disease  \n",
      "0                        3         3      Presence  \n",
      "1                        0         7       Absence  \n",
      "2                        0         7      Presence  \n",
      "3                        1         7       Absence  \n",
      "4                        1         3       Absence  \n",
      "Columns:  Index(['Age', 'Sex', 'Chest pain type', 'BP', 'Cholesterol', 'FBS over 120',\n",
      "       'EKG results', 'Max HR', 'Exercise angina', 'ST depression',\n",
      "       'Slope of ST', 'Number of vessels fluro', 'Thallium', 'Heart Disease'],\n",
      "      dtype='object')\n",
      "Ages: 0    70\n",
      "1    67\n",
      "2    57\n",
      "3    64\n",
      "4    74\n",
      "Name: Age, dtype: int64\n",
      "Cholesterol: 0    322\n",
      "1    564\n",
      "2    261\n",
      "3    263\n",
      "4    269\n",
      "Name: Cholesterol, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Example 6.2: Reading files with Pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/hd_data.csv')\n",
    "print(df.head()) # Print the first 5 rows of the DataFrame\n",
    "print(\"Columns: \", df.columns) # Print the column names\n",
    "print(\"Ages:\", df[\"Age\"].head()) # Print the first 5 values in the \"Age\" column\n",
    "print(\"Cholesterol:\", df[\"Cholesterol\"].head()) # Print the first 5 values in the \"Cholesterol\" column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d172bb8",
   "metadata": {},
   "source": [
    "## 7. Intro to Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f232e08",
   "metadata": {},
   "source": [
    "Scikit-learn is a popular python library for building and evaluating machine learning models. In the examples below, we make small models for classification and regression, then calculate metrics for the models to evaluate performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "875c94cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted heart disease for test set: ['Absence' 'Absence' 'Absence' 'Absence' 'Presence']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/hd_data.csv')\n",
    "#Features: pick a few relevant ones\n",
    "X = df[['Age', 'BP', 'Cholesterol', 'Max HR']]\n",
    "y = df['Heart Disease']  # target variable, this is what we will predict\n",
    "\n",
    "#Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Create and train model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict on test set\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"Predicted heart disease for test set:\", predictions[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4477c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Max HR for test set: [146.02857731 158.45157662 147.13197406 150.61168118 144.80808981]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/hd_data.csv')\n",
    "#Features: Age, BP, Cholesterol\n",
    "X = df[['Age', 'BP', 'Cholesterol']]\n",
    "y = df['Max HR']  # target variable\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "predicted = reg.predict(X_test)\n",
    "print(\"Predicted Max HR for test set:\", predicted[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be7a2504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.6419753086419753\n",
      "Classification recall: 0.53125\n",
      "Classification precision: 0.5483870967741935\n",
      "Regression R² score: 0.15768669328656026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/qychlp156sg4kxz17rtfgk6c0000gn/T/ipykernel_18391/982972689.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Heart Disease Numeric'] = df['Heart Disease'].replace({'Absence': 0, 'Presence': 1})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score, recall_score, precision_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/hd_data.csv')\n",
    "#Converting string labels into binary labels for classification\n",
    "df['Heart Disease Numeric'] = df['Heart Disease'].replace({'Absence': 0, 'Presence': 1})\n",
    "\n",
    "X_class = df[['Age', 'BP', 'Cholesterol', 'Max HR']]\n",
    "y_class = df['Heart Disease Numeric']\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
    "\n",
    "#Classification metrics: accuracy, recall, and precision\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_c, y_train_c)\n",
    "y_pred_class = clf.predict(X_test_c)\n",
    "accuracy = accuracy_score(y_test_c, y_pred_class)\n",
    "recall = recall_score(y_test_c, y_pred_class)\n",
    "precision = precision_score(y_test_c, y_pred_class)\n",
    "print(\"Classification accuracy:\", accuracy)\n",
    "print(\"Classification recall:\", recall)\n",
    "print(\"Classification precision:\", precision)\n",
    "\n",
    "\n",
    "X_reg = df[['Age', 'BP', 'Cholesterol']]\n",
    "y_reg = df['Max HR']\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "#Regression metric: R² score\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_r, y_train_r)\n",
    "y_pred_reg = reg.predict(X_test_r)\n",
    "r2 = r2_score(y_test_r, y_pred_reg)\n",
    "print(\"Regression R² score:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
